{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSORFLOW INTRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is based on the Youtube Video:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=PicxU81owCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KEY CONCEPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow provides a development interface to implement your ML model as a graph, where each node is an __operation__ (with any number of inputs and outputs) and each edge (=line connecting the nodes) are the tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorflow.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPES OF NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VARIABLES**: So, as can be seen in the chart above, __variables__ are _stateful_ nodes that output their current value (_stateful_ in this context means that their state -value- does not change accross multiple executions of a graph). Do  not miss that being nodes as they are, they are still __operations__ , although a type of operation that generates a fixed output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLACEHOLDERS**: are nodes whose value is input at the execution time. In the diagram above \"X\" and \"Y\" are placeholders. They have a __datatype__ and a __shape__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPERATIONS**: the last node type are __mathematical operations__. It is important not confusing these operations (\"TensorFlow Mathematical Operations\") with Numpy's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.zeros((100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W=tf.Variable(tf.random_uniform((784,100),-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,(100,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=tf.nn.relu(tf.matmul(x,W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the instructions above what we have built is a graph. No data has been entered in the system and consequently things do not \"do\" anything yet. What we have so far is just a __graph__ that we can operate. We can also visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we build the __graph__ TensorFlow adds a lot of stuff in the background. Lets take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'zeros' type=Const>,\n",
       " <tf.Operation 'Variable' type=VariableV2>,\n",
       " <tf.Operation 'Variable/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable/read' type=Identity>,\n",
       " <tf.Operation 'random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'random_uniform/min' type=Const>,\n",
       " <tf.Operation 'random_uniform/max' type=Const>,\n",
       " <tf.Operation 'random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'random_uniform' type=Add>,\n",
       " <tf.Operation 'Variable_1' type=VariableV2>,\n",
       " <tf.Operation 'Variable_1/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_1/read' type=Identity>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'Relu' type=Relu>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the level of __abstraction__ that TensorFlow brings above Python. When we __compute__ our graph, this is what will be computed behind the curtains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different methods to explore our graph. For instance we can list all the \"trainable\" variables with this call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(784, 100) dtype=float32_ref>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(784, 100) dtype=float32_ref>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables(scope=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph can be deployed by initiating a __session__. This session will have a context (i.e. running on CPU, or in GPU, etc). At the time of writing these lines, Google is providing their own hardware units, called TPU's (Tensor Processing Units) that are orders of magnitude faster than __GPU's__. So, properly speaking a session is a __hardware environment__ where the graph is going to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with sessions, we instantiate a __session object__ and then we __run__ it. The run method has two arguments:\n",
    "+ Fetches: this is the __list of graph nodes__ that return the -output- values of the nodes\n",
    "+ Feeds: this is a __dictionary__ that maps the graph nodes to specific values. Here is where we provide the inputs to the placeholders that we may have defined in our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, lets add some new lines to our graph to instantiate the graph and then run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.30966377,   0.        ,   8.26339149, ...,   0.        ,\n",
       "          8.225214  ,   0.        ],\n",
       "       [  6.37892866,   0.        ,   9.91442108, ...,   0.        ,\n",
       "          1.25263023,   0.        ],\n",
       "       [  0.        ,   0.        ,  12.53385639, ...,   0.        ,\n",
       "         10.06762123,   0.        ],\n",
       "       ..., \n",
       "       [  2.05970478,   0.        ,   0.        , ...,   2.15151715,\n",
       "          0.        ,   0.        ],\n",
       "       [  6.68823433,   0.        ,   3.90733528, ...,   0.        ,\n",
       "         14.41393375,   0.        ],\n",
       "       [  5.74209118,   0.        ,   4.84693432, ...,   0.        ,\n",
       "          6.43012857,   0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(h,{x:np.random.random_sample((100,784))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our graph deployed onto a session what we have is a __execution environment__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING THE ML MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to implement a Machine Learning model (in our case, a Neural Network) we need to define a __loss__ function. In Tensorflow we can use placeholders for labels and then specify a loss function using lables and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
